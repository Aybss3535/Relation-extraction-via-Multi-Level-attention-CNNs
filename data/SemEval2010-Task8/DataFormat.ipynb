{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9683e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1df403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel2id(read_filename,write_filename):\n",
    "    rels = set()\n",
    "    with open(read_filename,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            rel = line.strip().split('\\t')[1]\n",
    "            rels.add(rel)\n",
    "    rels = list(rels)\n",
    "    print(len(rels))\n",
    "    rel2id = {}\n",
    "    for i in range(len(rels)):\n",
    "        rel2id[rels[i]]=i\n",
    "    with open(write_filename,'w') as f:\n",
    "        json.dump(rel2id,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be4805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "get_rel2id('./train/train_result_full.txt','./SemEval2010-Task8_rel2id.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5573e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity2id(read_filename1,read_filename2,write_filename):\n",
    "    entities = set()\n",
    "    with open(read_filename1,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            curL = line.strip().split('\\t')[1]\n",
    "            e1 = curL[curL.index('<e1>')+4:curL.index('</e1>')]\n",
    "            e2 = curL[curL.index('<e2>')+4:curL.index('</e2>')]\n",
    "            entities.add(e1)\n",
    "            entities.add(e2)\n",
    "    with open(read_filename2,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            curL = line.strip().split('\\t')[1]\n",
    "            e1 = curL[curL.index('<e1>')+4:curL.index('</e1>')]\n",
    "            e2 = curL[curL.index('<e2>')+4:curL.index('</e2>')]\n",
    "            entities.add(e1)\n",
    "            entities.add(e2)\n",
    "    entities = list(entities)\n",
    "    entity2id = {}\n",
    "    for i in range(len(entities)):\n",
    "        entity2id[entities[i]] = i\n",
    "    with open(write_filename,'w') as f:\n",
    "        json.dump(entity2id,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d394aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_entity2id('./train/train.txt','./test/test.txt','./entity2id.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d6a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(filename_sen,filename_rel,rel2idPath,entity2idPath,write_filename):\n",
    "    with open(rel2idPath,'r') as f:\n",
    "        rel2id = json.load(f)\n",
    "    with open(entity2idPath,'r') as f:\n",
    "        entity2id = json.load(f)\n",
    "    rel = []\n",
    "    with open(filename_rel,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            rel.append(line.strip().split('\\t')[1])\n",
    "    i=0\n",
    "    with open(write_filename,'w') as fw:\n",
    "        with open(filename_sen,'r') as f:\n",
    "            for line in f.readlines():\n",
    "                data = {}\n",
    "                curL = line.strip().split('\\t')[1]\n",
    "                e1 = curL[curL.index('<e1>')+4:curL.index('</e1>')]\n",
    "                e2 = curL[curL.index('<e2>')+4:curL.index('</e2>')]\n",
    "                data['text'] = curL.replace('<e1>','').replace('</e1>','').replace('<e2>','').replace('</e2>','')\n",
    "                data['relation'] = rel[i]\n",
    "                i +=1\n",
    "                h = {}\n",
    "                h['pos'] = [data['text'].index(e1),data['text'].index(e1)+len(e1)]\n",
    "                h['name'] = e1\n",
    "                h['id'] = str(entity2id[e1])\n",
    "                data['h'] = h\n",
    "                t = {}\n",
    "                t['pos'] = [data['text'].index(e2),data['text'].index(e2)+len(e2)]\n",
    "                t['name'] = e2\n",
    "                t['id'] = str(entity2id[e2])\n",
    "                data['t'] = t\n",
    "                fw.write(str(data))\n",
    "                fw.write('\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c6c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatData('./train/train.txt','./train/train_result_full.txt','./SemEval2010-Task8_rel2id.json','./entity2id.json','./SemEval2010-Task8_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42adead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatData('./test/test.txt','./test/test_result_full.txt','./SemEval2010-Task8_rel2id.json','./entity2id.json','./SemEval2010-Task8_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd0c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}